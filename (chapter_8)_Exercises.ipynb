{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(chapter 8) Exercises.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4bpEhJFla5E8sDDzW5AeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anudeep22003/nlp-training/blob/main/(chapter_8)_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKF9A1Am167r",
        "outputId": "11c356ea-b3c4-4e1e-d18e-ca654052dc50"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, re, Tree\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk.corpus import conll2000\n",
        "nltk.download('conll2000')\n",
        "\n",
        "import math \n",
        "import random\n",
        "\n",
        "from nltk.corpus import treebank, ppattach\n",
        "nltk.download('treebank')\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('ppattach')\n",
        "\n",
        "!pip install printree\n",
        "from printree import ptree\n",
        "\n",
        "from textwrap import fill \n",
        "\n",
        "from timeit import Timer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]   Package ppattach is already up-to-date!\n",
            "Requirement already satisfied: printree in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFSQ0FDt2G7k"
      },
      "source": [
        "# Exercise 2 \n",
        "\n",
        "Recall Strunk and White's prohibition against sentence-initial however used to mean \"although\". Do a web search for however used at the start of the sentence. How widely used is this construction?\n",
        "\n",
        "> Ans: Quite rarely: ~0.3%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZjgJAnT4WGL",
        "outputId": "2293d96f-ae48-48b1-f0a7-7a26f49d20ed"
      },
      "source": [
        "tagged_sent = nltk.corpus.treebank.tagged_sents()\n",
        "l = len(tagged_sent)\n",
        "i = 0\n",
        "\n",
        "for sent in tagged_sent:\n",
        "  \n",
        "  if sent[0][0].lower() == 'however':\n",
        "    i+=1\n",
        "\n",
        "print(\"percent {:.2%}\".format((i/l)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percent 0.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ_ogN-W7bsU"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "Consider the sentence `Kim arrived or Dana left and everyone cheered`. Write down the parenthesized forms to show the relative scope of and and or. Generate tree structures corresponding to both of these interpretations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvoukjYF7n3I",
        "outputId": "d1ed7316-9f22-4618-fd12-bae0acff0f18"
      },
      "source": [
        "ex3_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> S PP S | NP VP\n",
        "  NP -> N\n",
        "  VP -> V\n",
        "  N -> 'Kim' | 'Dana' | 'everyone'\n",
        "  V -> 'arrived' | 'left' | 'cheered'\n",
        "  PP -> 'or' | 'and'\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "sent = \"Kim arrived or Dana left and everyone cheered\".split()\n",
        "\n",
        "rdp = nltk.ChartParser(ex3_grammar)\n",
        "\n",
        "for tree in rdp.parse(sent):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (S\n",
            "    (S (NP (N Kim)) (VP (V arrived)))\n",
            "    (PP or)\n",
            "    (S (NP (N Dana)) (VP (V left))))\n",
            "  (PP and)\n",
            "  (S (NP (N everyone)) (VP (V cheered))))\n",
            "(S\n",
            "  (S (NP (N Kim)) (VP (V arrived)))\n",
            "  (PP or)\n",
            "  (S\n",
            "    (S (NP (N Dana)) (VP (V left)))\n",
            "    (PP and)\n",
            "    (S (NP (N everyone)) (VP (V cheered)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x6xMbjcAvF3"
      },
      "source": [
        "# Exercise 6. \n",
        "Write a recursive function to traverse a tree and return the depth of the tree, such that a tree with a single node would have depth zero. (Hint: the depth of a subtree is the maximum depth of its children, plus one.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKmWPjKLByZU",
        "outputId": "b8c0bba5-cc97-4afd-90de-df4a81d38dc1"
      },
      "source": [
        "t1 = nltk.Tree('NP', ['Alice'])\n",
        "t2 = nltk.Tree('NP', ['the','rabbit'])\n",
        "t3 = nltk.Tree('VP',['chased', t2])\n",
        "t4 = nltk.Tree('S',[t1,t3])\n",
        "\n",
        "print(len(t3))\n",
        "for subtree in t1:\n",
        "  print(type(subtree))\n",
        "\n",
        "print(t3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "<class 'str'>\n",
            "(VP chased (NP the rabbit))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o68SGIPDVZp",
        "outputId": "1e841364-2cd8-475e-a5a1-46f647900be0"
      },
      "source": [
        "t = list(t1)\n",
        "print(t)\n",
        "print([type(i) for i in t])\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alice']\n",
            "[<class 'str'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTeQnWXXo9NR"
      },
      "source": [
        "all(isinstance(x, int) for x in lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW8tiEk_8839",
        "outputId": "96822005-b910-437f-d7eb-1854db7e0aca"
      },
      "source": [
        "def depth(tree):\n",
        "  \n",
        "  # base case:\n",
        "  if all(isinstance(leaves, int) for leaves in tree):\n",
        "    print(list(tree))\n",
        "    return (max(list(tree)))\n",
        "  \n",
        "  # if all are not ints then iterate over and derive depth of all tree type children\n",
        "  else:\n",
        "    for (i,child) in enumerate(list(tree)):\n",
        "      \n",
        "      if isinstance(child, nltk.Tree):\n",
        "        tree[i] = depth(child)+1\n",
        "      \n",
        "      # if not a tree type, then it is a leaf hence depth at that point is 1\n",
        "\n",
        "      # case for if the depth of the tree in focus has been calculated and depth is a number > 1 \n",
        "      elif isinstance(child, int) and child != 1:\n",
        "        continue\n",
        "      else: \n",
        "        tree[i] = 1\n",
        "    \n",
        "    return depth(tree)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(depth(t3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1]\n",
            "[1, 2]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaf6xllEBpJE"
      },
      "source": [
        "t = nltk.Tree.fromstring(\"(S (NP I (PP and (PP and (PP and (PP and)))) (V saw (V saw (V saw (V saw (V saw (V saw (V saw)))))))) (VP (V saw) (NP him (VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who(VP who))))))))))))))) (PP in (PP on)))))\")\n",
        "#t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
        "print(t)\n",
        "print(depth(t))\n",
        "print(t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLSPK5G0Ei74"
      },
      "source": [
        "# Exercise 7\n",
        "\n",
        "Analyze the A.A. Milne sentence about Piglet, by underlining all of the sentences it contains then replacing these with S (e.g. the first sentence becomes S when:lx` S). Draw a tree structure for this \"compressed\" sentence. What are the main syntactic constructions used for building such a long sentence?\n",
        "\n",
        "> They are using NP VP structure but are recursively modifying the NP or VP using auxilliary clauses of the form, Adj-Clause or Adverb-Clause"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSfBEHN8E1xC"
      },
      "source": [
        "piglet_sent = \"You can imagine Piglet's joy when at last the ship came in sight of him.] In after-years he liked to think that he had been in Very Great Danger during the Terrible Flood, but the only danger he had really been in was the last half-hour of his imprisonment, when Owl, who had just flown up, sat on a branch of his tree to comfort him, and told him a very long story about an aunt who had once laid a seagull's egg by mistake, and the story went on and on, rather like this sentence, until Piglet who was listening out of his window without much hope, went to sleep quietly and naturally, slipping slowly out of the window towards the water until he was only hanging on by his toes, at which moment, luckily, a sudden loud squawk from Owl, which was really part of the story, being what his aunt said, woke the Piglet up and just gave him time to jerk himself back into safety and say, \"How interesting, and did she?\" when — well, you can imagine his joy when at last he saw the good ship, Brain of Pooh (Captain, C. Robin; 1st Mate, P. Bear) coming over the sea to rescue him.\"\n",
        "\n",
        "S -> \"In after-years he liked to think that he had been in Very Great Danger during the Terrible Flood\" | \\\n",
        "    \"the only danger he had really been in was the last half-hour of his imprisonment\" | S PP S | \"told him a very long story about an aunt who had once laid a seagull's egg by mistake\" |\\\n",
        "    \"story went on and on\" | \"Owl, who had just flown up, sat on a branch of his tree to comfort him\" | \"told him a very long story about an aunt who had once laid a seagull's egg by mistake\" | \\\n",
        "    \"\"\n",
        "PP -> 'but' | \"and\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7-TcdwGNUEi",
        "outputId": "ece6cb67-98b0-4faa-bab2-caeb8618cc86"
      },
      "source": [
        "sent = \"S when (Owl, JJP, VP NP and VP NP JJP JJP) and (NP VP ADV-P ADV-P) until (N JJ-P ADV-P VP ADV-P, VP ADV-P) until (N V ADV-P) PP-DTV ADV-P NP JJ-P JJ-P, JJ-P, JJ-P VP NP ADV-P and ADV-P VP NP VP ADV-P) and VP ADV-P) when S\" \n",
        "\n",
        "print(fill(sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S when (Owl, JJP, VP NP and VP NP JJP JJP) and (NP VP ADV-P ADV-P)\n",
            "until (N JJ-P ADV-P VP ADV-P, VP ADV-P) until (N V ADV-P) PP-DTV ADV-P\n",
            "NP JJ-P JJ-P, JJ-P, JJ-P VP NP ADV-P and ADV-P VP NP VP ADV-P) and VP\n",
            "ADV-P) when S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9bMk2f2x2qN"
      },
      "source": [
        "# Exercise 9 \n",
        "\n",
        "☼ Can the grammar in grammar1 be used to describe sentences that are more than 20 words in length?\n",
        "\n",
        "> Yes, eg: ` John walked the dog in a park by the cat with Mary in a park by my dog on a man in telescope park`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdb3ZTeG5sE7"
      },
      "source": [
        "# Exercise 11\n",
        "\n",
        "With pen and paper, manually trace the execution of a recursive descent parser and a shift-reduce parser, for a CFG you have already seen, or one of your own devising.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Lo_jT1x6OK"
      },
      "source": [
        "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\"\n",
        "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
        "  \"\"\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aI1S_Ws5VyM",
        "outputId": "f64c5d28-650f-45e2-a18e-c26354174f5a"
      },
      "source": [
        "tokens = \"John saw Mary in the park\".split()\n",
        "\n",
        "rdp = nltk.RecursiveDescentParser(grammar1, trace = 2)\n",
        "cp = nltk.ChartParser(grammar1, trace = 3)\n",
        "\n",
        "print('\\n------- rdp parser ---------')\n",
        "\n",
        "for tree in rdp.parse(tokens):\n",
        "  print(tree)\n",
        "\n",
        "print('\\n------- cp parser ---------')\n",
        "\n",
        "for tree in cp.parse(tokens):\n",
        "  print(tree)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------- rdp parser ---------\n",
            "Parsing 'John saw Mary in the park'\n",
            "    [ * S ]\n",
            "  E [ * NP VP ]\n",
            "  E [ * 'John' VP ]\n",
            "  M [ 'John' * VP ]\n",
            "  E [ 'John' * V NP ]\n",
            "  E [ 'John' * 'saw' NP ]\n",
            "  M [ 'John' 'saw' * NP ]\n",
            "  E [ 'John' 'saw' * 'John' ]\n",
            "  E [ 'John' 'saw' * 'Mary' ]\n",
            "  M [ 'John' 'saw' 'Mary' ]\n",
            "  E [ 'John' 'saw' * 'Bob' ]\n",
            "  E [ 'John' 'saw' * Det N ]\n",
            "  E [ 'John' 'saw' * 'a' N ]\n",
            "  E [ 'John' 'saw' * 'an' N ]\n",
            "  E [ 'John' 'saw' * 'the' N ]\n",
            "  E [ 'John' 'saw' * 'my' N ]\n",
            "  E [ 'John' 'saw' * Det N PP ]\n",
            "  E [ 'John' 'saw' * 'a' N PP ]\n",
            "  E [ 'John' 'saw' * 'an' N PP ]\n",
            "  E [ 'John' 'saw' * 'the' N PP ]\n",
            "  E [ 'John' 'saw' * 'my' N PP ]\n",
            "  E [ 'John' * 'ate' NP ]\n",
            "  E [ 'John' * 'walked' NP ]\n",
            "  E [ 'John' * V NP PP ]\n",
            "  E [ 'John' * 'saw' NP PP ]\n",
            "  M [ 'John' 'saw' * NP PP ]\n",
            "  E [ 'John' 'saw' * 'John' PP ]\n",
            "  E [ 'John' 'saw' * 'Mary' PP ]\n",
            "  M [ 'John' 'saw' 'Mary' * PP ]\n",
            "  E [ 'John' 'saw' 'Mary' * P NP ]\n",
            "  E [ 'John' 'saw' 'Mary' * 'in' NP ]\n",
            "  M [ 'John' 'saw' 'Mary' 'in' * NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'John' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'Mary' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'Bob' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * Det N ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'a' N ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'an' N ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'the' N ]\n",
            "  M [ 'John' 'saw' 'Mary' 'in' 'the' * N ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'man' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'dog' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'cat' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'telescope' ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'park' ]\n",
            "  M [ 'John' 'saw' 'Mary' 'in' 'the' 'park' ]\n",
            "  + [ 'John' 'saw' 'Mary' 'in' 'the' 'park' ]\n",
            "(S\n",
            "  (NP John)\n",
            "  (VP (V saw) (NP Mary) (PP (P in) (NP (Det the) (N park)))))\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'my' N ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * Det N PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'a' N PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'an' N PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'the' N PP ]\n",
            "  M [ 'John' 'saw' 'Mary' 'in' 'the' * N PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'man' PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'dog' PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'cat' PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'telescope' PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' * 'park' PP ]\n",
            "  M [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * PP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * P NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * 'in' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * 'on' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * 'by' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' 'the' 'park' * 'with' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' 'in' * 'my' N PP ]\n",
            "  E [ 'John' 'saw' 'Mary' * 'on' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' * 'by' NP ]\n",
            "  E [ 'John' 'saw' 'Mary' * 'with' NP ]\n",
            "  E [ 'John' 'saw' * 'Bob' PP ]\n",
            "  E [ 'John' 'saw' * Det N PP ]\n",
            "  E [ 'John' 'saw' * 'a' N PP ]\n",
            "  E [ 'John' 'saw' * 'an' N PP ]\n",
            "  E [ 'John' 'saw' * 'the' N PP ]\n",
            "  E [ 'John' 'saw' * 'my' N PP ]\n",
            "  E [ 'John' 'saw' * Det N PP PP ]\n",
            "  E [ 'John' 'saw' * 'a' N PP PP ]\n",
            "  E [ 'John' 'saw' * 'an' N PP PP ]\n",
            "  E [ 'John' 'saw' * 'the' N PP PP ]\n",
            "  E [ 'John' 'saw' * 'my' N PP PP ]\n",
            "  E [ 'John' * 'ate' NP PP ]\n",
            "  E [ 'John' * 'walked' NP PP ]\n",
            "  E [ * 'Mary' VP ]\n",
            "  E [ * 'Bob' VP ]\n",
            "  E [ * Det N VP ]\n",
            "  E [ * 'a' N VP ]\n",
            "  E [ * 'an' N VP ]\n",
            "  E [ * 'the' N VP ]\n",
            "  E [ * 'my' N VP ]\n",
            "  E [ * Det N PP VP ]\n",
            "  E [ * 'a' N PP VP ]\n",
            "  E [ * 'an' N PP VP ]\n",
            "  E [ * 'the' N PP VP ]\n",
            "  E [ * 'my' N PP VP ]\n",
            "\n",
            "------- cp parser ---------\n",
            "|. John . saw  . Mary .  in  . the  . park .|\n",
            "Leaf Init Rule:\n",
            "|[------]      .      .      .      .      .| [0:1] 'John'\n",
            "|.      [------]      .      .      .      .| [1:2] 'saw'\n",
            "|.      .      [------]      .      .      .| [2:3] 'Mary'\n",
            "|.      .      .      [------]      .      .| [3:4] 'in'\n",
            "|.      .      .      .      [------]      .| [4:5] 'the'\n",
            "|.      .      .      .      .      [------]| [5:6] 'park'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[------]      .      .      .      .      .| [0:1] NP -> 'John' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[------>      .      .      .      .      .| [0:1] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      [------]      .      .      .      .| [1:2] V  -> 'saw' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      [------>      .      .      .      .| [1:2] VP -> V * NP\n",
            "|.      [------>      .      .      .      .| [1:2] VP -> V * NP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      [------]      .      .      .| [2:3] NP -> 'Mary' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      [------>      .      .      .| [2:3] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.      [-------------]      .      .      .| [1:3] VP -> V NP *\n",
            "|.      [------------->      .      .      .| [1:3] VP -> V NP * PP\n",
            "Single Edge Fundamental Rule:\n",
            "|[--------------------]      .      .      .| [0:3] S  -> NP VP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      [------]      .      .| [3:4] P  -> 'in' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      [------>      .      .| [3:4] PP -> P * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      .      [------]      .| [4:5] Det -> 'the' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      .      [------>      .| [4:5] NP -> Det * N\n",
            "|.      .      .      .      [------>      .| [4:5] NP -> Det * N PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      .      .      [------]| [5:6] N  -> 'park' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.      .      .      .      [-------------]| [4:6] NP -> Det N *\n",
            "|.      .      .      .      [------------->| [4:6] NP -> Det N * PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.      .      .      .      [------------->| [4:6] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.      .      .      [--------------------]| [3:6] PP -> P NP *\n",
            "Single Edge Fundamental Rule:\n",
            "|.      [----------------------------------]| [1:6] VP -> V NP PP *\n",
            "Single Edge Fundamental Rule:\n",
            "|[=========================================]| [0:6] S  -> NP VP *\n",
            "(S\n",
            "  (NP John)\n",
            "  (VP (V saw) (NP Mary) (PP (P in) (NP (Det the) (N park)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ez3g6nQBysd"
      },
      "source": [
        "# Exercise 12\n",
        "\n",
        "We have seen that a chart parser adds but never removes edges from a chart. Why?\n",
        "\n",
        "> Because each substring is considered only once, and even if there are competitng grammatical interpretations one wins out and then that substring is not touched. Hence the removal never happens. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRz3Y3U5DtcT"
      },
      "source": [
        "# Exercise 13\n",
        "\n",
        "Consider the sequence of words: Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo. This is a grammatically correct sentence, as explained at http://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo. Consider the tree diagram presented on this Wikipedia page, and write down a suitable grammar. Normalize case to lowercase, to simulate the problem that a listener has when hearing this sentence. Can you find other parses for this sentence? How does the number of parse trees grow as the sentence gets longer? (More examples of these sentences can be found at http://en.wikipedia.org/wiki/List_of_homophonous_phrases).\n",
        "\n",
        "> Only ChartParser worked here. \n",
        "\n",
        "- Recursive descent parser, exceeded its recursive depth because of the RC rule \n",
        "- shift reduct parse also failed because the second time it came across an NP V it got pulled into the RC rule, whereas the RC rule is only valid once. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulgo90KMD3vX",
        "outputId": "13ed955a-f217-40fe-9b46-1890430c3950"
      },
      "source": [
        "tokens = \"Buffalo buuffalo Buffalo buuffalo buffalo buffalo Buffalo buuffalo\".split()\n",
        "\n",
        "grammar_buffalo = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP \n",
        "  NP -> JJ N | NP RC\n",
        "  VP -> V NP\n",
        "  RC -> NP V\n",
        "  N -> 'buuffalo'\n",
        "  JJ -> 'Buffalo' \n",
        "  V -> 'buffalo' \n",
        "\"\"\")\n",
        "\n",
        "cp = nltk.ChartParser(grammar_buffalo, trace = 2)\n",
        "\n",
        "for tree in cp.parse(tokens):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|.Buff.buuf.Buff.buuf.buff.buff.Buff.buuf.|\n",
            "Leaf Init Rule:\n",
            "|[----]    .    .    .    .    .    .    .| [0:1] 'Buffalo'\n",
            "|.    [----]    .    .    .    .    .    .| [1:2] 'buuffalo'\n",
            "|.    .    [----]    .    .    .    .    .| [2:3] 'Buffalo'\n",
            "|.    .    .    [----]    .    .    .    .| [3:4] 'buuffalo'\n",
            "|.    .    .    .    [----]    .    .    .| [4:5] 'buffalo'\n",
            "|.    .    .    .    .    [----]    .    .| [5:6] 'buffalo'\n",
            "|.    .    .    .    .    .    [----]    .| [6:7] 'Buffalo'\n",
            "|.    .    .    .    .    .    .    [----]| [7:8] 'buuffalo'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[----]    .    .    .    .    .    .    .| [0:1] JJ -> 'Buffalo' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[---->    .    .    .    .    .    .    .| [0:1] NP -> JJ * N\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    [----]    .    .    .    .    .    .| [1:2] N  -> 'buuffalo' *\n",
            "Single Edge Fundamental Rule:\n",
            "|[---------]    .    .    .    .    .    .| [0:2] NP -> JJ N *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[--------->    .    .    .    .    .    .| [0:2] S  -> NP * VP\n",
            "|[--------->    .    .    .    .    .    .| [0:2] NP -> NP * RC\n",
            "|[--------->    .    .    .    .    .    .| [0:2] RC -> NP * V\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    [----]    .    .    .    .    .| [2:3] JJ -> 'Buffalo' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    [---->    .    .    .    .    .| [2:3] NP -> JJ * N\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    [----]    .    .    .    .| [3:4] N  -> 'buuffalo' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.    .    [---------]    .    .    .    .| [2:4] NP -> JJ N *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    [--------->    .    .    .    .| [2:4] S  -> NP * VP\n",
            "|.    .    [--------->    .    .    .    .| [2:4] NP -> NP * RC\n",
            "|.    .    [--------->    .    .    .    .| [2:4] RC -> NP * V\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    [----]    .    .    .| [4:5] V  -> 'buffalo' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    [---->    .    .    .| [4:5] VP -> V * NP\n",
            "Single Edge Fundamental Rule:\n",
            "|.    .    [--------------]    .    .    .| [2:5] RC -> NP V *\n",
            "Single Edge Fundamental Rule:\n",
            "|[------------------------]    .    .    .| [0:5] NP -> NP RC *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[------------------------>    .    .    .| [0:5] S  -> NP * VP\n",
            "|[------------------------>    .    .    .| [0:5] NP -> NP * RC\n",
            "|[------------------------>    .    .    .| [0:5] RC -> NP * V\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    [----]    .    .| [5:6] V  -> 'buffalo' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    [---->    .    .| [5:6] VP -> V * NP\n",
            "Single Edge Fundamental Rule:\n",
            "|[-----------------------------]    .    .| [0:6] RC -> NP V *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    .    [----]    .| [6:7] JJ -> 'Buffalo' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    .    [---->    .| [6:7] NP -> JJ * N\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    .    .    [----]| [7:8] N  -> 'buuffalo' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.    .    .    .    .    .    [---------]| [6:8] NP -> JJ N *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.    .    .    .    .    .    [--------->| [6:8] S  -> NP * VP\n",
            "|.    .    .    .    .    .    [--------->| [6:8] NP -> NP * RC\n",
            "|.    .    .    .    .    .    [--------->| [6:8] RC -> NP * V\n",
            "Single Edge Fundamental Rule:\n",
            "|.    .    .    .    .    [--------------]| [5:8] VP -> V NP *\n",
            "Single Edge Fundamental Rule:\n",
            "|[=======================================]| [0:8] S  -> NP VP *\n",
            "(S\n",
            "  (NP\n",
            "    (NP (JJ Buffalo) (N buuffalo))\n",
            "    (RC (NP (JJ Buffalo) (N buuffalo)) (V buffalo)))\n",
            "  (VP (V buffalo) (NP (JJ Buffalo) (N buuffalo))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26gKWnafcrnc"
      },
      "source": [
        "# Exercise 15\n",
        "\n",
        "Extend the grammar in grammar2 with productions that expand prepositions as intransitive, transitive and requiring a PP complement. Based on these productions, use the method of the preceding exercise to draw a tree for the sentence Lee ran away home.\n",
        "\n",
        "> Exercise does not make sense. What's a transitive and intransitive preposition and why this grammar when there is literally no overlap with the given sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EylFqkGKcpz4"
      },
      "source": [
        "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
        "  S  -> NP VP\n",
        "  NP -> Det Nom | PropN\n",
        "  Nom -> Adj Nom | N\n",
        "  VP -> V Adj | V NP | V S | V NP PP\n",
        "  PP -> P NP\n",
        "  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
        "  Det -> 'the' | 'a'\n",
        "  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
        "  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
        "  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
        "  P -> 'on'\n",
        "  \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aLBLpzCeCax"
      },
      "source": [
        "# Exercise 16\n",
        "\n",
        "Pick some common verbs and complete the following tasks:\n",
        "\n",
        "Write a program to find those verbs in the Prepositional Phrase Attachment Corpus nltk.corpus.ppattach. Find any cases where the same verb exhibits two different attachments, but where the first noun, or second noun, or preposition, stay unchanged (as we saw in our discussion of syntactic ambiguity in 2).\n",
        "Devise CFG grammar productions to cover some of these cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2buFlE5heRt0",
        "outputId": "afb8fa66-1829-43e2-c298-628ff4499ae4"
      },
      "source": [
        "pp = ppattach.attachments('training')\n",
        "\n",
        "for pp_chunk in pp[315:350]:\n",
        "  if pp_chunk.attachment == 'N':\n",
        "    print(\"type: N {:8s} --> {}\".format(pp_chunk.noun1, pp_chunk.prep))\n",
        "  else:\n",
        "    print(\"type: V {}, {} --> {}\".format(pp_chunk.verb, pp_chunk.noun1, pp_chunk.prep))\n",
        "\n",
        "\n",
        "#print(l.noun1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type: V pumping, assistance --> into\n",
            "type: V voice, optimism --> about\n",
            "type: N undertone --> of\n",
            "type: N understanding --> on\n",
            "type: V expand, functions --> in\n",
            "type: V approach, it --> with\n",
            "type: V be, gain --> for\n",
            "type: V regard, presence --> as\n",
            "type: V step, investments --> in\n",
            "type: N Test     --> of\n",
            "type: V giving, Test --> to\n",
            "type: N example  --> of\n",
            "type: V matched, answers --> on\n",
            "type: V had, answers --> to\n",
            "type: V surrendered, notes --> without\n",
            "type: V use, notes --> on\n",
            "type: N one      --> of\n",
            "type: V given, questions --> to\n",
            "type: V display, questions --> on\n",
            "type: V was, days --> in\n",
            "type: N one      --> of\n",
            "type: N something --> of\n",
            "type: V casts, light --> on\n",
            "type: N provisions --> of\n",
            "type: V win, bonus --> under\n",
            "type: N pressure --> on\n",
            "type: N responsibility --> for\n",
            "type: V changed, answers --> to\n",
            "type: V force, districts --> into\n",
            "type: N score    --> of\n",
            "type: V use, SAT --> as\n",
            "type: V paying, price --> by\n",
            "type: N one      --> of\n",
            "type: N way      --> for\n",
            "type: V take, it --> at\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtMA0TiGkNhR"
      },
      "source": [
        "# Write a program to find those verbs in the Prepositional Phrase Attachment Corpus nltk.corpus.ppattach. \n",
        "# Find any cases where the same verb exhibits two different attachments, \n",
        "# but where the first noun, or second noun, or preposition, stay unchanged \n",
        "\n",
        "common_verbs = \"is was are runs walks lifts\".split()\n",
        "\n",
        "pp_list = ppattach.attachments('training')\n",
        "\n",
        "l = [(pp.verb, pp.attachment, set([pp.noun1, pp.noun2, pp.prep])) for pp in pp_list if pp.verb in common_verbs]\n",
        "\n",
        "print(len(l))\n",
        "pprint(l[3:7])\n",
        "\n",
        " \n",
        "\n",
        "for i in range(len(l)):\n",
        "  for j in range(i+1,len(l)):\n",
        "    if l[i][:2] == l[j][:2] and l[i][2] & l[j][2]:\n",
        "      print(\"Attachment type: {} sent1: {} and sent2 {}\".format(l[i][:2],l[i], l[j]))\n",
        "\n",
        "\n",
        "\n",
        "pp_dict = {'{}+{}'.format(pp.verb, pp.attachment): set([pp.noun1, pp.noun2, pp.prep])\n",
        "           for pp in pp_list \n",
        "           if pp.verb in common_verbs}\n",
        "\n",
        "# mydict = {k: v for k, v in iterable}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toBInhr9C41w",
        "outputId": "cfa4ff84-1b07-4688-e989-be68aea29a93"
      },
      "source": [
        "\n",
        "print(pp_dict.keys())\n",
        "print(pp_dict['was+N'])\n",
        "\n",
        "print([len(list(pp_dict[key])) for key in pp_dict.keys()])\n",
        "\n",
        "print(type(pp_dict['was+N']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['is+N', 'was+N', 'is+V', 'are+N', 'was+V', 'are+V', 'runs+V', 'runs+N'])\n",
            "{'of', 'example', 'democracy'}\n",
            "[3, 3, 3, 3, 3, 3, 3, 3]\n",
            "<class 'set'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qWvL52M8FBB",
        "outputId": "1ee966d2-d0df-41f5-fd75-d13f99664582"
      },
      "source": [
        "pp[345]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PPAttachment(sent='683', verb='use', noun1='SAT', prep='as', noun2='examination', attachment='V')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWX_7XEi9nt"
      },
      "source": [
        "# Exercise 17\n",
        "\n",
        "Write a program to compare the efficiency of a top-down chart parser compared with a recursive descent parser (4). Use the same grammar and input sentences for both. Compare their performance using the timeit module (see 4.7 for an example of how to do this)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqoDjQGHjHID",
        "outputId": "af3723d6-6e46-4599-b40b-81b32f39bd1f"
      },
      "source": [
        "sent = \"I go to the market to buy shoes\".split()\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> NP VP\n",
        "  VP -> V NP\n",
        "  NP -> N | Det N | PP | PP PP\n",
        "  PP -> P VP | P NP\n",
        "\n",
        "  N -> 'I' | 'shoes' | 'market'\n",
        "  V -> 'go' | 'buy'\n",
        "  Det -> 'the'\n",
        "  P -> 'to'\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "def print_tree(parser, sent):\n",
        "  for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "\n",
        "cp = nltk.ChartParser(grammar)\n",
        "rdp = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "print_tree(cp, sent)\n",
        "\n",
        "print('\\n------------------------------------------------\\n')\n",
        "\n",
        "print_tree(rdp, sent)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (N I))\n",
            "  (VP\n",
            "    (V go)\n",
            "    (NP\n",
            "      (PP (P to) (NP (Det the) (N market)))\n",
            "      (PP (P to) (VP (V buy) (NP (N shoes)))))))\n",
            "\n",
            "------------------------------------------------\n",
            "\n",
            "(S\n",
            "  (NP (N I))\n",
            "  (VP\n",
            "    (V go)\n",
            "    (NP\n",
            "      (PP (P to) (NP (Det the) (N market)))\n",
            "      (PP (P to) (VP (V buy) (NP (N shoes)))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318MpcXw3ver"
      },
      "source": [
        "# code that is executed once \n",
        "setup = \"import nltk\"\n",
        "\n",
        "mycode = '''\n",
        "sent = \"I go to the market to buy shoes to go to the market\".split()\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> NP VP\n",
        "  VP -> V NP\n",
        "  NP -> N | Det N | PP | PP PP\n",
        "  PP -> P VP | P NP\n",
        "\n",
        "  N -> 'I' | 'shoes' | 'market'\n",
        "  V -> 'go' | 'buy'\n",
        "  Det -> 'the'\n",
        "  P -> 'to'\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "def print_tree(parser, sent):\n",
        "  for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "\n",
        "cp = nltk.ChartParser(grammar)\n",
        "\n",
        "print_tree(cp, sent)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# code that is executed multiple times\n",
        "statement = \"print_tree(cp, sent)\"\n",
        "\n",
        "cp_time = Timer(mycode, setup).timeit(10)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Hhx1_W6qTo"
      },
      "source": [
        "# code that is executed once \n",
        "setup = \"import nltk\"\n",
        "\n",
        "# code that is executed multiple times\n",
        "\n",
        "mycode = '''\n",
        "sent = \"I go to the market to buy shoes to go to the market\".split()\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> NP VP\n",
        "  VP -> V NP\n",
        "  NP -> N | Det N | PP | PP PP\n",
        "  PP -> P VP | P NP\n",
        "\n",
        "  N -> 'I' | 'shoes' | 'market'\n",
        "  V -> 'go' | 'buy'\n",
        "  Det -> 'the'\n",
        "  P -> 'to'\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "def print_tree(parser, sent):\n",
        "  for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "\n",
        "rdp = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "print_tree(rdp, sent)\n",
        "\n",
        "'''\n",
        "\n",
        "rdp_time = Timer(mycode, setup).timeit(10)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4qanqBm8N1r",
        "outputId": "2a8dd794-36dc-4299-d9fa-cb6018265f46"
      },
      "source": [
        "print(cp_time)\n",
        "print(rdp_time)\n",
        "print(\"\\ncp is {} magnitudes faster than rdp\".format(rdp_time/cp_time))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02421919600055844\n",
            "0.10591669299992645\n",
            "\n",
            "cp is 4.373253884954903 magnitudes faster than rdp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrkZFj313ns_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}