{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(chapter 9) Exercises.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMSAAFf6QQSQ8kJytDg0ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anudeep22003/nlp-training/blob/main/(chapter_9)_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ImFLkacNLAB",
        "outputId": "32593171-e823-4bce-f98f-b3593bc8d892"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, re\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "from nltk.corpus import conll2000\n",
        "nltk.download('conll2000')\n",
        "\n",
        "import math \n",
        "import random\n",
        "\n",
        "from nltk.corpus import treebank\n",
        "nltk.download('treebank')\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('ppattach')\n",
        "\n",
        "\n",
        "nltk.download('book_grammars')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data] Downloading package book_grammars to /root/nltk_data...\n",
            "[nltk_data]   Unzipping grammars/book_grammars.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pyfGYvfNQ5S"
      },
      "source": [
        "# Exercise 1 \n",
        "\n",
        "☼ What constraints are required to correctly parse word sequences like I am happy and she is happy but not *you is happy or *they am happy? Implement two solutions for the present tense paradigm of the verb be in English, first taking Grammar (6) as your starting point, and then taking Grammar (18) as the starting point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jky5BvWtNlje",
        "outputId": "e7f46849-4652-43d5-eee6-0c55b5e5322c"
      },
      "source": [
        "sentc_1 = \"I am happy\".split()\n",
        "sentc_2 = \"she is happy\".split()\n",
        "\n",
        "sentw_1 = \"you is happy\".split()\n",
        "sentw_2 = \"they am happy\".split()\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> NP_1_SG VP_1_SG      \n",
        "  S -> NP_3_SG VP_3_SG      \n",
        "  S -> NP_3_PL VP_3_PL      \n",
        "  S -> NP_2_SG VP_2_SG      \n",
        "\n",
        "  NP_1_SG -> RB_1_SG \n",
        "  VP_1_SG -> V_1_SG N                                                                                     \n",
        "\n",
        "  NP_3_SG -> RB_3_SG\n",
        "  VP_3_SG -> V_3_SG N\n",
        "\n",
        "  NP_2_SG -> RB_2_SG \n",
        "  VP_2_SG -> V_2_SG N\n",
        "\n",
        "  NP_3_PL -> RB_3_PL\n",
        "  VP_3_PL -> V_3_PL N\n",
        "\n",
        "  RB_1_SG -> \"I\"\n",
        "  RB_3_SG -> \"she\"\n",
        "  RB_2_SG -> \"you\"\n",
        "  RB_3_PL -> \"they\"\n",
        "  \n",
        "  N -> \"happy\"\n",
        "\n",
        "  V_1_SG -> \"am\"\n",
        "  V_3_SG -> \"is\"\n",
        "  V_2_SG -> \"are\"\n",
        "  V_3_PL -> \"are\"\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "rdp = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "for tree in rdp.parse(sentc_1):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP_1_SG (RB_1_SG I)) (VP_1_SG (V_1_SG am) (N happy)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHCNWVwuVEtg"
      },
      "source": [
        "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP[AGR=?n] VP[AGR=?n]\n",
        "  NP[AGR=?n] = RB[AGR=?n]\n",
        "  VP[TENSE=?t, AGR=?n] -> V[TENSE=?t, AGR=?n] N\n",
        "\n",
        "  RB[AGR=[PER=1, NUM=SG]] -> \"I\"\n",
        "  RB[AGR=[PER=2, NUM=SG]] -> \"you\"\n",
        "  RB[AGR=[PER=3, NUM=SG]] -> \"she\"\n",
        "  RB[AGR=[PER=3, NUM=PL]] -> \"they\"\n",
        "\n",
        "  V[TENSE = pres, AGR=[PER=1, NUM=SG]] -> \"am\"\n",
        "  V[TENSE = pres, AGR=[PER=2, NUM=SG]] -> \"are\"\n",
        "  V[TENSE = pres, AGR=[PER=3, NUM=SG]] -> \"is\"\n",
        "  V[TENSE = pres, AGR=[PER=3, NUM=PL]] -> \"are\"\n",
        "\n",
        "  N -> \"happy\"\n",
        "\n",
        "\"\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7wIB7Pde7m_"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "☼ Develop a variant of grammar in 1.1 that uses a feature count to make the distinctions shown below:\n",
        "\n",
        "```\n",
        "(54)\t\t\n",
        "a.\t\tThe boy sings.\n",
        "b.\t\t*Boy sings.\n",
        "\n",
        "(55)\t\t\n",
        "a.\t\tThe boys sing.\n",
        "b.\t\tBoys sing.\n",
        "\n",
        "(56)\t\t\n",
        "a.\t\tThe boys sing.\n",
        "b.\t\tBoys sing.\n",
        "\n",
        "(57)\t\t\n",
        "a.\t\tThe water is precious.\n",
        "b.\t\tWater is precious.\n",
        "\n",
        "```\n",
        "\n",
        "--- \n",
        "\n",
        "Handled all the cases except for the `Boy sings.` being wrong. It is not clear to me if that structure is wrong, and if it is how do I diffferentiate that case from the others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snl_cz2ve2Ou"
      },
      "source": [
        "\"\"\"\n",
        "############################\n",
        "## Grammar Produtions ##\n",
        "############################\n",
        "\n",
        "## S Expansion Productions\n",
        "\n",
        "S -> NP[NUM=?N] VP[NUM=?N]\n",
        "\n",
        "NP[NUM=?n] -> Det N[NUM=?n]\n",
        "NP[NUM=pl] -> N[NUM=pl]\n",
        "\n",
        "VP[NUM=?n] -> IV[NUM=?n]\n",
        "VP[NUM=?n] -> TV[NUM=?n] N\n",
        "\n",
        "############################\n",
        "#### Lexical Produtions ####\n",
        "############################\n",
        "\n",
        "Det -> 'the'\n",
        "N[NUM=sg] -> 'boy' | 'water'\n",
        "N[NUM=pl] -> 'boys'\n",
        "N -> 'precious'\n",
        "\n",
        "IV[NUM=sg] -> 'sings'\n",
        "IV[NUM=pl] -> 'sing'\n",
        "TV[NUM=sg] -> 'is'\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BJiOPnhmBfz"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "☼ Write a function subsumes() which holds of two feature structures fs1 and fs2 just in case fs1 subsumes fs2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dX7oSP6mHRC",
        "outputId": "808cb5a6-f060-44d2-a4a3-c27c693a040b"
      },
      "source": [
        "fs_agr = nltk.FeatStruct(PER=3, NUM = 'pl', GND = 'fem')\n",
        "fs_tense_pres = nltk.FeatStruct(TENSE = 'pres')\n",
        "fs_id = nltk.FeatStruct(NAME = 'ANUDEEP')\n",
        "fs_address = nltk.FeatStruct(HOUSE_NUMBER=79, STREET = \"5th MAIN\", CITY = \"BANGALORE\")\n",
        "\n",
        "fs_combo = nltk.FeatStruct(fs_id, ADDRESS = fs_address)\n",
        "\n",
        "def subsumes(fs1, fs2):\n",
        "  if fs1.unify(fs2) == fs2:\n",
        "    return fs1, fs2\n",
        "    \n",
        "  elif fs1.unify(fs2) == fs1:\n",
        "    return fs2, fs1 \n",
        "  \n",
        "  else:\n",
        "    return fs1, fs2, fs1.unify(fs2)\n",
        "  \n",
        "\n",
        "print(subsumes(fs_id, fs_address), end ='\\n\\n')\n",
        "\n",
        "print('\\n------------------------------------\\n')\n",
        "\n",
        "print(fs_combo)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([NAME='ANUDEEP'], [CITY='BANGALORE', HOUSE_NUMBER=79, STREET='5th MAIN'], [CITY='BANGALORE', HOUSE_NUMBER=79, NAME='ANUDEEP', STREET='5th MAIN'])\n",
            "\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "[           [ CITY         = 'BANGALORE' ] ]\n",
            "[ ADDRESS = [ HOUSE_NUMBER = 79          ] ]\n",
            "[           [ STREET       = '5th MAIN'  ] ]\n",
            "[                                          ]\n",
            "[ NAME    = 'ANUDEEP'                      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbC-H1qiGbA6"
      },
      "source": [
        "# Exercise 4. \n",
        "\n",
        "☼ Modify the grammar illustrated in (28) to incorporate a bar feature for dealing with phrasal projections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5EA7MA2G7NW"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=intrans, TENSE=?t, NUM=?n]\n",
        "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=trans, TENSE=?t, NUM=?n] NP\n",
        "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=clause, TENSE=?t, NUM=?n] SBar\n",
        "\n",
        "V[SUBCAT=intrans, TENSE=pres, NUM=sg] -> 'disappears' | 'walks'\n",
        "V[SUBCAT=trans, TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
        "V[SUBCAT=clause, TENSE=pres, NUM=sg] -> 'says' | 'claims'\n",
        "\n",
        "V[SUBCAT=intrans, TENSE=pres, NUM=pl] -> 'disappear' | 'walk'\n",
        "V[SUBCAT=trans, TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
        "V[SUBCAT=clause, TENSE=pres, NUM=pl] -> 'say' | 'claim'\n",
        "\n",
        "V[SUBCAT=intrans, TENSE=past, NUM=?n] -> 'disappeared' | 'walked'\n",
        "V[SUBCAT=trans, TENSE=past, NUM=?n] -> 'saw' | 'liked'\n",
        "V[SUBCAT=clause, TENSE=past, NUM=?n] -> 'said' | 'claimed'\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KesQOlQgJV4E"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "S -> N[BAR=2] V[BAR=2]\n",
        "N[BAR=2] -> N[BAR=1]\n",
        "N[BAR=1] -> N[BAR=0] XS\n",
        "\n",
        "V[BAR=2] -> V[BAR=1]\n",
        "V[BAR=1] -> V[BAR=1] N[BAR=2]\n",
        "V[BAR=1] -> V[BAR=1] PP[BAR=2]\n",
        "V[BAR=1] -> V[BAR=0] XS\n",
        "\n",
        "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=clause, TENSE=?t, NUM=?n] SBar\n",
        "\n",
        "SBar/PP[BAR=2] -> P[BAR=1]\n",
        "P[BAR=1] -> P[BAR=1] S\n",
        "P[BAR=1] -> P[BAR=0] XS\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iu23h25emZ"
      },
      "source": [
        "# Exercise 5\n",
        "\n",
        "☼ Modify the German grammar in 3.2 to incorporate the treatment of subcategorization presented in 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwEvPVXO5lvD"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        " # Grammar Productions\n",
        "\n",
        " S -> NP[CASE=nom, AGR=?a] VP[AGR=?a]\n",
        " NP[CASE=?c, AGR=?a] -> PRO[CASE=?c, AGR=?a]\n",
        " NP[CASE=?c, AGR=?a] -> Det[CASE=?c, AGR=?a] N[CASE=?c, AGR=?a]\n",
        " VP[AGR=?a] -> V[SUBCAT=IV, AGR=?a]\n",
        " VP[AGR=?a] -> V[SUBCAT=TV, OBJCASE=?C, AGR=?A] NP[CASE=?c]\n",
        "\n",
        " \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fB5ltSG894rk",
        "outputId": "c0f6ebe8-9c82-47c9-c09e-9d5d8dfef692"
      },
      "source": [
        "nltk.parse.earleychart.demo(print_grammar=True, trace=4)\n",
        "\n",
        "\"\"\"\n",
        "1. Initialize an entire leaf table \n",
        "2. Start Loop:\n",
        "  - Start state -> starts with the S production state \n",
        "      Sets the dot at pos i=0, with all the production rules to the right\n",
        "  \n",
        "  - Predictor -> reads the productions, and finds the rules that start with value immediately to the right of the dot\n",
        "      looks up all the productions and finds all the rules and adds them to the \"processing queue\"\n",
        "  \n",
        "  - Scanner -> finds the rule in the \"processing queue\" that ends in a terminal and matches the symbol received, and moves the dot to the right \n",
        "\n",
        "  - Completer -> \n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Grammar\n",
            "Grammar with 18 productions (start state = S)\n",
            "    S -> NP VP\n",
            "    PP -> 'with' NP\n",
            "    NP -> NP PP\n",
            "    VP -> VP PP\n",
            "    VP -> Verb NP\n",
            "    VP -> Verb\n",
            "    NP -> Det Noun\n",
            "    NP -> 'John'\n",
            "    NP -> 'I'\n",
            "    Det -> 'the'\n",
            "    Det -> 'my'\n",
            "    Det -> 'a'\n",
            "    Noun -> 'dog'\n",
            "    Noun -> 'cookie'\n",
            "    Verb -> 'ate'\n",
            "    Verb -> 'saw'\n",
            "    Prep -> 'with'\n",
            "    Prep -> 'under'\n",
            "* Sentence:\n",
            "I saw John with a dog with my cookie\n",
            "['I', 'saw', 'John', 'with', 'a', 'dog', 'with', 'my', 'cookie']\n",
            "\n",
            "|. I  .saw .John.with. a  .dog .with. my .cook.|\n",
            "Leaf Init Rule:\n",
            "|[----]    .    .    .    .    .    .    .    .| [0:1] 'I'\n",
            "|.    [----]    .    .    .    .    .    .    .| [1:2] 'saw'\n",
            "|.    .    [----]    .    .    .    .    .    .| [2:3] 'John'\n",
            "|.    .    .    [----]    .    .    .    .    .| [3:4] 'with'\n",
            "|.    .    .    .    [----]    .    .    .    .| [4:5] 'a'\n",
            "|.    .    .    .    .    [----]    .    .    .| [5:6] 'dog'\n",
            "|.    .    .    .    .    .    [----]    .    .| [6:7] 'with'\n",
            "|.    .    .    .    .    .    .    [----]    .| [7:8] 'my'\n",
            "|.    .    .    .    .    .    .    .    [----]| [8:9] 'cookie'\n",
            "Top Down Init Rule:\n",
            "|>    .    .    .    .    .    .    .    .    .| [0:0] S  -> * NP VP\n",
            "\n",
            "* Processing queue: 0 \n",
            "\n",
            "Predictor Rule:\n",
            "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * NP PP\n",
            "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * Det Noun\n",
            "|>    .    .    .    .    .    .    .    .    .| [0:0] NP -> * 'I'\n",
            "\n",
            "* Processing queue: 1 \n",
            "\n",
            "Scanner Rule:\n",
            "|[----]    .    .    .    .    .    .    .    .| [0:1] NP -> 'I' *\n",
            "Completer Rule:\n",
            "|[---->    .    .    .    .    .    .    .    .| [0:1] S  -> NP * VP\n",
            "|[---->    .    .    .    .    .    .    .    .| [0:1] NP -> NP * PP\n",
            "Predictor Rule:\n",
            "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * VP PP\n",
            "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * Verb NP\n",
            "|.    >    .    .    .    .    .    .    .    .| [1:1] VP -> * Verb\n",
            "Predictor Rule:\n",
            "|.    >    .    .    .    .    .    .    .    .| [1:1] Verb -> * 'saw'\n",
            "\n",
            "* Processing queue: 2 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    [----]    .    .    .    .    .    .    .| [1:2] Verb -> 'saw' *\n",
            "Completer Rule:\n",
            "|.    [---->    .    .    .    .    .    .    .| [1:2] VP -> Verb * NP\n",
            "|.    [----]    .    .    .    .    .    .    .| [1:2] VP -> Verb *\n",
            "Completer Rule:\n",
            "|[---------]    .    .    .    .    .    .    .| [0:2] S  -> NP VP *\n",
            "|.    [---->    .    .    .    .    .    .    .| [1:2] VP -> VP * PP\n",
            "Predictor Rule:\n",
            "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * NP PP\n",
            "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * Det Noun\n",
            "|.    .    >    .    .    .    .    .    .    .| [2:2] NP -> * 'John'\n",
            "\n",
            "* Processing queue: 3 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    [----]    .    .    .    .    .    .| [2:3] NP -> 'John' *\n",
            "Completer Rule:\n",
            "|.    [---------]    .    .    .    .    .    .| [1:3] VP -> Verb NP *\n",
            "|.    .    [---->    .    .    .    .    .    .| [2:3] NP -> NP * PP\n",
            "Predictor Rule:\n",
            "|.    .    .    >    .    .    .    .    .    .| [3:3] PP -> * 'with' NP\n",
            "Completer Rule:\n",
            "|[--------------]    .    .    .    .    .    .| [0:3] S  -> NP VP *\n",
            "|.    [--------->    .    .    .    .    .    .| [1:3] VP -> VP * PP\n",
            "\n",
            "* Processing queue: 4 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    [---->    .    .    .    .    .| [3:4] PP -> 'with' * NP\n",
            "Predictor Rule:\n",
            "|.    .    .    .    >    .    .    .    .    .| [4:4] NP -> * NP PP\n",
            "|.    .    .    .    >    .    .    .    .    .| [4:4] NP -> * Det Noun\n",
            "Predictor Rule:\n",
            "|.    .    .    .    >    .    .    .    .    .| [4:4] Det -> * 'a'\n",
            "\n",
            "* Processing queue: 5 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    .    [----]    .    .    .    .| [4:5] Det -> 'a' *\n",
            "Completer Rule:\n",
            "|.    .    .    .    [---->    .    .    .    .| [4:5] NP -> Det * Noun\n",
            "Predictor Rule:\n",
            "|.    .    .    .    .    >    .    .    .    .| [5:5] Noun -> * 'dog'\n",
            "\n",
            "* Processing queue: 6 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    .    .    [----]    .    .    .| [5:6] Noun -> 'dog' *\n",
            "Completer Rule:\n",
            "|.    .    .    .    [---------]    .    .    .| [4:6] NP -> Det Noun *\n",
            "Completer Rule:\n",
            "|.    .    .    [--------------]    .    .    .| [3:6] PP -> 'with' NP *\n",
            "|.    .    .    .    [--------->    .    .    .| [4:6] NP -> NP * PP\n",
            "Predictor Rule:\n",
            "|.    .    .    .    .    .    >    .    .    .| [6:6] PP -> * 'with' NP\n",
            "Completer Rule:\n",
            "|.    .    [-------------------]    .    .    .| [2:6] NP -> NP PP *\n",
            "|.    [------------------------]    .    .    .| [1:6] VP -> VP PP *\n",
            "Completer Rule:\n",
            "|[-----------------------------]    .    .    .| [0:6] S  -> NP VP *\n",
            "|.    [------------------------>    .    .    .| [1:6] VP -> VP * PP\n",
            "Completer Rule:\n",
            "|.    [------------------------]    .    .    .| [1:6] VP -> Verb NP *\n",
            "|.    .    [------------------->    .    .    .| [2:6] NP -> NP * PP\n",
            "Completer Rule:\n",
            "|[-----------------------------]    .    .    .| [0:6] S  -> NP VP *\n",
            "|.    [------------------------>    .    .    .| [1:6] VP -> VP * PP\n",
            "\n",
            "* Processing queue: 7 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    .    .    .    [---->    .    .| [6:7] PP -> 'with' * NP\n",
            "Predictor Rule:\n",
            "|.    .    .    .    .    .    .    >    .    .| [7:7] NP -> * NP PP\n",
            "|.    .    .    .    .    .    .    >    .    .| [7:7] NP -> * Det Noun\n",
            "Predictor Rule:\n",
            "|.    .    .    .    .    .    .    >    .    .| [7:7] Det -> * 'my'\n",
            "\n",
            "* Processing queue: 8 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    .    .    .    .    [----]    .| [7:8] Det -> 'my' *\n",
            "Completer Rule:\n",
            "|.    .    .    .    .    .    .    [---->    .| [7:8] NP -> Det * Noun\n",
            "Predictor Rule:\n",
            "|.    .    .    .    .    .    .    .    >    .| [8:8] Noun -> * 'cookie'\n",
            "\n",
            "* Processing queue: 9 \n",
            "\n",
            "Scanner Rule:\n",
            "|.    .    .    .    .    .    .    .    [----]| [8:9] Noun -> 'cookie' *\n",
            "Completer Rule:\n",
            "|.    .    .    .    .    .    .    [---------]| [7:9] NP -> Det Noun *\n",
            "Completer Rule:\n",
            "|.    .    .    .    .    .    [--------------]| [6:9] PP -> 'with' NP *\n",
            "|.    .    .    .    .    .    .    [--------->| [7:9] NP -> NP * PP\n",
            "Completer Rule:\n",
            "|.    .    .    .    [------------------------]| [4:9] NP -> NP PP *\n",
            "|.    [---------------------------------------]| [1:9] VP -> VP PP *\n",
            "|.    .    [----------------------------------]| [2:9] NP -> NP PP *\n",
            "Completer Rule:\n",
            "|.    [---------------------------------------]| [1:9] VP -> Verb NP *\n",
            "|.    .    [---------------------------------->| [2:9] NP -> NP * PP\n",
            "Completer Rule:\n",
            "|[============================================]| [0:9] S  -> NP VP *\n",
            "|.    [--------------------------------------->| [1:9] VP -> VP * PP\n",
            "Completer Rule:\n",
            "|[============================================]| [0:9] S  -> NP VP *\n",
            "|.    [--------------------------------------->| [1:9] VP -> VP * PP\n",
            "Completer Rule:\n",
            "|.    .    .    [-----------------------------]| [3:9] PP -> 'with' NP *\n",
            "|.    .    .    .    [------------------------>| [4:9] NP -> NP * PP\n",
            "Completer Rule:\n",
            "|.    .    [----------------------------------]| [2:9] NP -> NP PP *\n",
            "|.    [---------------------------------------]| [1:9] VP -> VP PP *\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (Verb saw)\n",
            "    (NP\n",
            "      (NP (NP John) (PP with (NP (Det a) (Noun dog))))\n",
            "      (PP with (NP (Det my) (Noun cookie))))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (Verb saw)\n",
            "    (NP\n",
            "      (NP John)\n",
            "      (PP\n",
            "        with\n",
            "        (NP\n",
            "          (NP (Det a) (Noun dog))\n",
            "          (PP with (NP (Det my) (Noun cookie))))))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog))))\n",
            "    (PP with (NP (Det my) (Noun cookie)))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog)))))\n",
            "    (PP with (NP (Det my) (Noun cookie)))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (Verb saw) (NP John))\n",
            "    (PP\n",
            "      with\n",
            "      (NP\n",
            "        (NP (Det a) (Noun dog))\n",
            "        (PP with (NP (Det my) (Noun cookie)))))))\n",
            "Time: 0.055352999999996655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n1. Initialize an entire leaf table \\n2. Start Loop:\\n  - Start state -> starts with the S production state \\n      Sets the dot at pos i=0, with all the production rules to the right\\n  \\n  - Predictor -> reads the productions, and finds the rules that start with value immediately to the right of the dot\\n      looks up all the productions and finds all the rules and adds them to the \"processing queue\"\\n  \\n  - Scanner -> finds the rule in the \"processing queue\" that ends in a terminal and matches the symbol received, and moves the dot to the right \\n\\n  - Completer -> \\n\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUJxTyZn5igv"
      },
      "source": [
        "# Exercise 8\n",
        "\n",
        "Work out on paper what the result is of the following unifications. (Hint: you might find it useful to draw the graph structures.)\n",
        "\n",
        "- fs1 and fs2\n",
        "- fs1 and fs3\n",
        "- fs4 and fs5\n",
        "- fs5 and fs6\n",
        "- fs5 and fs7\n",
        "- fs8 and fs9\n",
        "- fs8 and fs10\n",
        "\n",
        "Check your answers using Python.\n",
        "\n",
        "\n",
        "```\n",
        "fs1 = nltk.FeatStruct(\"[A = ?x, B= [C = ?x]]\")\n",
        "fs2 = nltk.FeatStruct(\"[B = [D = d]]\")\n",
        "fs3 = nltk.FeatStruct(\"[B = [C = d]]\")\n",
        "fs4 = nltk.FeatStruct(\"[A = (1)[B = b], C->(1)]\")\n",
        "fs5 = nltk.FeatStruct(\"[A = (1)[D = ?x], C = [E -> (1), F = ?x] ]\")\n",
        "fs6 = nltk.FeatStruct(\"[A = [D = d]]\")\n",
        "fs7 = nltk.FeatStruct(\"[A = [D = d], C = [F = [D = d]]]\")\n",
        "fs8 = nltk.FeatStruct(\"[A = (1)[D = ?x, G = ?x], C = [B = ?x, E -> (1)] ]\")\n",
        "fs9 = nltk.FeatStruct(\"[A = [B = b], C = [E = [G = e]]]\")\n",
        "fs10 = nltk.FeatStruct(\"[A = (1)[B = b], C -> (1)]\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI4Vz6XQ7tiH"
      },
      "source": [
        "fs1 = nltk.FeatStruct(\"[A = ?x, B= [C = ?x]]\")\n",
        "fs2 = nltk.FeatStruct(\"[B = [D = d]]\")\n",
        "fs3 = nltk.FeatStruct(\"[B = [C = d]]\")\n",
        "fs4 = nltk.FeatStruct(\"[A = (1)[B = b], C->(1)]\")\n",
        "fs5 = nltk.FeatStruct(\"[A = (1)[D = ?x], C = [E -> (1), F = ?x] ]\")\n",
        "fs6 = nltk.FeatStruct(\"[A = [D = d]]\")\n",
        "fs7 = nltk.FeatStruct(\"[A = [D = d], C = [F = [D = d]]]\")\n",
        "\n",
        "fs8 = nltk.FeatStruct(\"[A = (1)[D = ?x, G = ?x], C = [B = ?x, E -> (1)] ]\")\n",
        "\n",
        "fs9 = nltk.FeatStruct(\"[A = [B = b], C = [E = [G = e]]]\")\n",
        "\n",
        "\n",
        "fs8 = nltk.FeatStruct(\"[A = (1)[D = ?x, G = ?x], C = [B = ?x, E -> (1)] ]\")\n",
        "fs10 = nltk.FeatStruct(\"[A = (1)[B = b], C -> (1)]\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rewudvt9TGS",
        "outputId": "24865e77-b238-4460-ca9f-2c32942844ac"
      },
      "source": [
        "print(fs1.unify(fs2))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs1.unify(fs3))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs4.unify(fs5))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs6.unify(fs5))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs5.unify(fs7))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs8.unify(fs9))\n",
        "print(\"\\n----------------------\\n\")\n",
        "print(fs8.unify(fs10))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ A = ?x          ]\n",
            "[                 ]\n",
            "[ B = [ C = ?x  ] ]\n",
            "[     [ D = 'd' ] ]\n",
            "\n",
            "----------------------\n",
            "\n",
            "[ A = 'd'         ]\n",
            "[                 ]\n",
            "[ B = [ C = 'd' ] ]\n",
            "\n",
            "----------------------\n",
            "\n",
            "[         [ B = 'b'  ] ]\n",
            "[ A = (1) [ D = ?x   ] ]\n",
            "[         [ E -> (1) ] ]\n",
            "[         [ F = ?x   ] ]\n",
            "[                      ]\n",
            "[ C -> (1)             ]\n",
            "\n",
            "----------------------\n",
            "\n",
            "[ A = (1) [ D = 'd' ] ]\n",
            "[                     ]\n",
            "[ C = [ E -> (1) ]    ]\n",
            "[     [ F = 'd'  ]    ]\n",
            "\n",
            "----------------------\n",
            "\n",
            "None\n",
            "\n",
            "----------------------\n",
            "\n",
            "[         [ B = 'b' ] ]\n",
            "[ A = (1) [ D = 'e' ] ]\n",
            "[         [ G = 'e' ] ]\n",
            "[                     ]\n",
            "[ C = [ B = 'e'  ]    ]\n",
            "[     [ E -> (1) ]    ]\n",
            "\n",
            "----------------------\n",
            "\n",
            "[         [ B = 'b'  ] ]\n",
            "[ A = (1) [ D = 'b'  ] ]\n",
            "[         [ E -> (1) ] ]\n",
            "[         [ G = 'b'  ] ]\n",
            "[                      ]\n",
            "[ C -> (1)             ]\n"
          ]
        }
      ]
    }
  ]
}