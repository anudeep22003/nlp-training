{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(chapter 9) Exercises.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHlQ/E3/NuMR2bVqjwpxhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anudeep22003/nlp-training/blob/main/(chapter_9)_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ImFLkacNLAB",
        "outputId": "f4f2a855-aeb6-4d4c-fc88-997a60a01f83"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, re\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "from nltk.corpus import conll2000\n",
        "nltk.download('conll2000')\n",
        "\n",
        "import math \n",
        "import random\n",
        "\n",
        "from nltk.corpus import treebank\n",
        "nltk.download('treebank')\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('ppattach')\n",
        "\n",
        "\n",
        "nltk.download('book_grammars')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data] Downloading package book_grammars to /root/nltk_data...\n",
            "[nltk_data]   Unzipping grammars/book_grammars.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pyfGYvfNQ5S"
      },
      "source": [
        "# Exercise 1 \n",
        "\n",
        "☼ What constraints are required to correctly parse word sequences like I am happy and she is happy but not *you is happy or *they am happy? Implement two solutions for the present tense paradigm of the verb be in English, first taking Grammar (6) as your starting point, and then taking Grammar (18) as the starting point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jky5BvWtNlje",
        "outputId": "e7f46849-4652-43d5-eee6-0c55b5e5322c"
      },
      "source": [
        "sentc_1 = \"I am happy\".split()\n",
        "sentc_2 = \"she is happy\".split()\n",
        "\n",
        "sentw_1 = \"you is happy\".split()\n",
        "sentw_2 = \"they am happy\".split()\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "  S -> NP_1_SG VP_1_SG      \n",
        "  S -> NP_3_SG VP_3_SG      \n",
        "  S -> NP_3_PL VP_3_PL      \n",
        "  S -> NP_2_SG VP_2_SG      \n",
        "\n",
        "  NP_1_SG -> RB_1_SG \n",
        "  VP_1_SG -> V_1_SG N                                                                                     \n",
        "\n",
        "  NP_3_SG -> RB_3_SG\n",
        "  VP_3_SG -> V_3_SG N\n",
        "\n",
        "  NP_2_SG -> RB_2_SG \n",
        "  VP_2_SG -> V_2_SG N\n",
        "\n",
        "  NP_3_PL -> RB_3_PL\n",
        "  VP_3_PL -> V_3_PL N\n",
        "\n",
        "  RB_1_SG -> \"I\"\n",
        "  RB_3_SG -> \"she\"\n",
        "  RB_2_SG -> \"you\"\n",
        "  RB_3_PL -> \"they\"\n",
        "  \n",
        "  N -> \"happy\"\n",
        "\n",
        "  V_1_SG -> \"am\"\n",
        "  V_3_SG -> \"is\"\n",
        "  V_2_SG -> \"are\"\n",
        "  V_3_PL -> \"are\"\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "rdp = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "for tree in rdp.parse(sentc_1):\n",
        "  print(tree)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP_1_SG (RB_1_SG I)) (VP_1_SG (V_1_SG am) (N happy)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHCNWVwuVEtg"
      },
      "source": [
        "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP[AGR=?n] VP[AGR=?n]\n",
        "  NP[AGR=?n] = RB[AGR=?n]\n",
        "  VP[TENSE=?t, AGR=?n] -> V[TENSE=?t, AGR=?n] N\n",
        "\n",
        "  RB[AGR=[PER=1, NUM=SG]] -> \"I\"\n",
        "  RB[AGR=[PER=2, NUM=SG]] -> \"you\"\n",
        "  RB[AGR=[PER=3, NUM=SG]] -> \"she\"\n",
        "  RB[AGR=[PER=3, NUM=PL]] -> \"they\"\n",
        "\n",
        "  V[TENSE = pres, AGR=[PER=1, NUM=SG]] -> \"am\"\n",
        "  V[TENSE = pres, AGR=[PER=2, NUM=SG]] -> \"are\"\n",
        "  V[TENSE = pres, AGR=[PER=3, NUM=SG]] -> \"is\"\n",
        "  V[TENSE = pres, AGR=[PER=3, NUM=PL]] -> \"are\"\n",
        "\n",
        "  N -> \"happy\"\n",
        "\n",
        "\"\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7wIB7Pde7m_"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "☼ Develop a variant of grammar in 1.1 that uses a feature count to make the distinctions shown below:\n",
        "\n",
        "```\n",
        "(54)\t\t\n",
        "a.\t\tThe boy sings.\n",
        "b.\t\t*Boy sings.\n",
        "\n",
        "(55)\t\t\n",
        "a.\t\tThe boys sing.\n",
        "b.\t\tBoys sing.\n",
        "\n",
        "(56)\t\t\n",
        "a.\t\tThe boys sing.\n",
        "b.\t\tBoys sing.\n",
        "\n",
        "(57)\t\t\n",
        "a.\t\tThe water is precious.\n",
        "b.\t\tWater is precious.\n",
        "\n",
        "```\n",
        "\n",
        "--- \n",
        "\n",
        "Handled all the cases except for the `Boy sings.` being wrong. It is not clear to me if that structure is wrong, and if it is how do I diffferentiate that case from the others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snl_cz2ve2Ou"
      },
      "source": [
        "\"\"\"\n",
        "############################\n",
        "## Grammar Produtions ##\n",
        "############################\n",
        "\n",
        "## S Expansion Productions\n",
        "\n",
        "S -> NP[NUM=?N] VP[NUM=?N]\n",
        "\n",
        "NP[NUM=?n] -> Det N[NUM=?n]\n",
        "NP[NUM=pl] -> N[NUM=pl]\n",
        "\n",
        "VP[NUM=?n] -> IV[NUM=?n]\n",
        "VP[NUM=?n] -> TV[NUM=?n] N\n",
        "\n",
        "############################\n",
        "#### Lexical Produtions ####\n",
        "############################\n",
        "\n",
        "Det -> 'the'\n",
        "N[NUM=sg] -> 'boy' | 'water'\n",
        "N[NUM=pl] -> 'boys'\n",
        "N -> 'precious'\n",
        "\n",
        "IV[NUM=sg] -> 'sings'\n",
        "IV[NUM=pl] -> 'sing'\n",
        "TV[NUM=sg] -> 'is'\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BJiOPnhmBfz"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "☼ Write a function subsumes() which holds of two feature structures fs1 and fs2 just in case fs1 subsumes fs2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dX7oSP6mHRC",
        "outputId": "547cee93-8f7c-4fb9-de76-664ad9d85054"
      },
      "source": [
        "fs_agr = nltk.FeatStruct(PER=3, NUM = 'pl', GND = 'fem')\n",
        "fs_tense_pres = nltk.FeatStruct(TENSE = 'pres')\n",
        "fs_id = nltk.FeatStruct(NAME = 'LEE')\n",
        "fs_address = nltk.FeatStruct(HOUSE_NUMBER=79, STREET = \"5th MAIN\", CITY = \"BANGALORE\")\n",
        "fs_combo = nltk.FeatStruct(fs_id, ADDRESS = fs_address)\n",
        "\n",
        "def subsumes(fs1, fs2):\n",
        "  if fs1.unify(fs2) == fs2:\n",
        "    return fs1, fs2\n",
        "    \n",
        "  elif fs1.unify(fs2) == fs1:\n",
        "    return fs2, fs1 \n",
        "  \n",
        "  else:\n",
        "    return fs1, fs2, fs1.unify(fs2)\n",
        "  \n",
        "\n",
        "print(subsumes(fs_id, fs_address))\n",
        "print(fs_combo)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([NAME='LEE'], [CITY='BANGALORE', HOUSE_NUMBER=79, STREET='5th MAIN'], [CITY='BANGALORE', HOUSE_NUMBER=79, NAME='LEE', STREET='5th MAIN'])\n",
            "[           [ CITY         = 'BANGALORE' ] ]\n",
            "[ ADDRESS = [ HOUSE_NUMBER = 79          ] ]\n",
            "[           [ STREET       = '5th MAIN'  ] ]\n",
            "[                                          ]\n",
            "[ NAME    = 'LEE'                          ]\n"
          ]
        }
      ]
    }
  ]
}